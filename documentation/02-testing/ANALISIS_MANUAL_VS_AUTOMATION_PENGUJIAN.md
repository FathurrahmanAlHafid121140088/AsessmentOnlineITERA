# Analisis Manual vs Automation - Pengujian Non-Fungsional
## Assessment Online ITERA - Mental Health System

**Tanggal Dokumen:** 26 November 2025
**Status:** Analisis Perbandingan Komprehensif
**Focus:** Effort, Cost, Quality, Time, Risk

---

## Daftar Isi

1. [Executive Summary](#executive-summary)
2. [Manual Testing - Detail Analysis](#manual-testing---detail-analysis)
3. [Automation Testing - Detail Analysis](#automation-testing---detail-analysis)
4. [Perbandingan Langsung (Side by Side)](#perbandingan-langsung-side-by-side)
5. [Studi Kasus Real](#studi-kasus-real)
6. [Cost & ROI Analysis](#cost--roi-analysis)
7. [Hybrid Approach (Recommended)](#hybrid-approach-recommended)
8. [Decision Matrix](#decision-matrix)

---

## Executive Summary

### **Kesimpulan Singkat:**

| Aspek | Manual | Automation | Winner |
|-------|--------|-----------|--------|
| **Effort Setup** | âœ… Rendah (jam) | âŒ Tinggi (hari) | Manual |
| **Effort Repeat** | âŒ Tinggi (setiap kali) | âœ… Rendah (1 klik) | Automation |
| **Total Time (1 tahun)** | âŒ 400+ jam | âœ… 40 jam | Automation (10x lebih cepat) |
| **Cost (1 tahun)** | âŒ $5,000-10,000 | âœ… $1,000-2,000 | Automation |
| **Quality** | âŒ 70% (human error) | âœ… 95%+ (konsisten) | Automation |
| **Coverage** | âš ï¸ 40-50% | âœ… 80-90% | Automation |
| **Bug Detection** | âš ï¸ Slow (1-2 minggu) | âœ… Fast (dalam CI/CD) | Automation |
| **Regression Risk** | âŒ Tinggi | âœ… Rendah | Automation |
| **Mudah Dimulai** | âœ… Yes | âŒ Complex | Manual |

---

## Manual Testing - Detail Analysis

### Pengertian
Manual testing = Tester menjalankan test cases secara manual, click-by-click, menggunakan browser dan tools UI tanpa automation script.

### Contoh Workflow Manual

**Test Case: Security - CSRF Token Protection**

```
1. Buka browser Chrome
   Time: 30 detik

2. Navigate ke http://localhost:8000/mental-health/isi-data-diri
   Time: 1 menit

3. Buka Chrome DevTools (F12)
   Time: 30 detik

4. Inspect form HTML:
   - Cari hidden input dengan name="_token"
   - Copy value CSRF token
   Time: 2 menit

5. Buka Postman
   Time: 30 detik

6. Setup POST request:
   - URL: http://localhost:8000/submit-form
   - Body: nama=John&usia=20
   - (Jangan include CSRF token)
   Time: 1 menit

7. Send request & verify response
   - Expected: HTTP 419 "Page Expired"
   Time: 1 menit

8. Repeat dengan token yang salah
   Time: 2 menit

9. Repeat dengan token yang benar
   Time: 2 menit

10. Document hasil & screenshot
    Time: 3 menit

TOTAL TIME PER TEST: ~15 menit
```

---

### Manual Testing - Keuntungan

âœ… **Mudah Dimulai**
- Tidak perlu setup kompleks
- Langsung bisa mulai testing
- Tidak perlu coding skills

âœ… **Exploratory Testing**
- Test behavior tidak terduga (monkey testing)
- User experience perspective
- Discover edge cases

âœ… **Visual & UX Testing**
- Visual bugs (layout tidak aligned)
- Color issues
- Responsive design issues
- User interaction feedback

âœ… **Ad-hoc Testing**
- Quick testing tanpa planning
- Rapid feedback loop
- Real user perspective

âœ… **Low Initial Cost**
- Tidak perlu tool license (rata-rata)
- Minimal setup infrastructure

---

### Manual Testing - Kerugian

âŒ **Time Consuming**
- Setiap test harus dijalankan ulang dari awal
- 15 menit Ã— 39 test cases = 9+ jam untuk 1x testing cycle
- Pengembang testing 5 kali/minggu = 45 jam/minggu

âŒ **Human Error Prone**
- Forget steps
- Click wrong button
- Miss details
- Inconsistent execution
- Error rate: 10-30%

âŒ **Not Scalable**
- Testing time meningkat linear dengan features
- Untuk 100 test cases = 25+ jam
- Untuk 1000 test cases = 250+ jam

âŒ **No Evidence/Audit Trail**
- Sulit document hasil jika ada disagreement
- Screenshot manual saja tidak cukup
- Compliance testing butuh full trace

âŒ **Regression Testing Nightmare**
- Setiap update harus test semua cases lagi
- Developers resisting testing karena memakan waktu
- Features tidak di-test properly â†’ bug di production

âŒ **Tidak Reusable**
- Setiap kali test, harus mulai dari awal
- Tidak ada test asset untuk reuse

âŒ **Resource Intensive**
- Need dedicated tester
- Need good documentation (pedantic)
- Training time tinggi

---

### Manual Testing - Worst Case Scenario

```
Timeline untuk Assessment Online (39 test cases):

Week 1: Setup & training
  - Baca dokumentasi: 8 jam
  - Setup tools (Postman, browser, etc): 4 jam
  - Learn application: 8 jam
  Total: 20 jam

Week 2-3: First round testing
  - 39 test cases Ã— 15 menit = 9.75 jam (first time)
  - Issues found â†’ debug â†’ retry: 10 jam
  - Documentation & reporting: 8 hours
  Total: ~28 jam

Week 4: Fix & retest
  - Bugs ditemukan di week 2-3
  - Developers fix
  - Tester re-test: 9.75 jam
  - Report hasil: 4 jam
  Total: ~14 jam

TOTAL FIRST CYCLE: 62 jam (~2 minggu kerja 1 orang tester)

---

Kalau ada bug ditemukan di production:
  - Tester harus retest semua 39 cases: 9.75 jam
  - Per bug fix: 9.75 jam
  - Untuk 5 bugs: 49 jam (1+ minggu)

---

Maintenance (1 tahun):
  - Retest per feature update: 39 cases Ã— 15 menit = 9.75 jam
  - Average: 2 updates/bulan = 19.5 jam/bulan
  - Per tahun: 19.5 Ã— 12 = 234 jam/tahun

TOTAL EFFORT 1 TAHUN: 62 + 234 = 296 jam
```

---

## Automation Testing - Detail Analysis

### Pengertian
Automation testing = Scripts yang dijalankan otomatis, dapat dijalankan berulang, terintegrasi dengan CI/CD pipeline.

### Contoh Workflow Automation

**Test Case: Security - CSRF Token Protection (Cypress)**

```javascript
// cypress/e2e/csrf-protection.cy.js

describe('CSRF Token Protection', () => {
  it('should return 419 when CSRF token missing', () => {
    // Step 1-4 dalam manual (navigate, inspect)
    // â†’ Automated dalam 1 line:
    cy.visit('/mental-health/isi-data-diri');

    // Get CSRF token dari hidden input
    cy.get('input[name="_token"]').then(($token) => {
      const csrfToken = $token.val();

      // Step 5-7 (setup Postman request)
      // â†’ Automated:
      cy.request({
        method: 'POST',
        url: '/submit-form',
        form: true,
        body: {
          nama: 'John',
          usia: 20
          // Jangan include _token
        },
        failOnStatusCode: false // expect 419
      }).then((response) => {
        // Step 7-10 (verify)
        expect(response.status).to.equal(419);
        expect(response.body).to.include('Page Expired');
      });
    });
  });

  it('should return 419 when CSRF token invalid', () => {
    cy.visit('/mental-health/isi-data-diri');

    cy.request({
      method: 'POST',
      url: '/submit-form',
      form: true,
      body: {
        nama: 'John',
        usia: 20,
        _token: 'invalid-token-12345'
      },
      failOnStatusCode: false
    }).then((response) => {
      expect(response.status).to.equal(419);
    });
  });

  it('should succeed when CSRF token valid', () => {
    cy.visit('/mental-health/isi-data-diri');

    cy.get('input[name="_token"]').then(($token) => {
      const csrfToken = $token.val();

      cy.request({
        method: 'POST',
        url: '/submit-form',
        form: true,
        body: {
          nama: 'John',
          usia: 20,
          _token: csrfToken
        }
      }).then((response) => {
        expect(response.status).to.be.oneOf([200, 302]);
      });
    });
  });
});
```

**Run Test (1 command):**
```bash
npx cypress run --spec cypress/e2e/csrf-protection.cy.js

# Hasil:
# âœ“ should return 419 when CSRF token missing (0.5 detik)
# âœ“ should return 419 when CSRF token invalid (0.4 detik)
# âœ“ should succeed when CSRF token valid (0.6 detik)
#
# 3 passed (1.5 detik)
```

**TIME: 1.5 detik vs 45 menit (manual) = 1800x lebih cepat! ğŸš€**

---

### Automation Testing - Keuntungan

âœ… **Sangat Cepat**
- First run: 3-5 test cases/detik
- 39 test cases: ~10-15 detik
- Repeat run: sama cepat (tidak tambah waktu)

âœ… **100% Konsisten**
- Tidak ada human error
- Setiap run sama persis
- 0% chance typo atau lupa step

âœ… **Highly Scalable**
- 100 test cases: 25-30 detik
- 1000 test cases: 250-300 detik
- Linear dengan test count, bukan manual

âœ… **Reusable Assets**
- Write once, run 1000x
- ROI meningkat setiap kali dijalankan
- Test code bisa di-refactor untuk multiple scenarios

âœ… **CI/CD Integration**
- Auto-run pada setiap push
- Block merge jika test fail
- 24/7 continuous testing
- Immediate feedback (3-5 menit)

âœ… **Regression Prevention**
- Semua test otomatis, jadi developer tidak takut breaking changes
- Developer lebih confident refactor
- Bugs caught early (sebelum production)

âœ… **Full Audit Trail**
- Detailed logs setiap step
- Video recording (Cypress, Playwright)
- Easy to debug failures
- Compliance-friendly

âœ… **Cost Effective (Long Term)**
- Initial setup: 2-3 hari
- ROI break-even: ~3 minggu
- Menghemat waktu developer 200+ jam/tahun

---

### Automation Testing - Kerugian

âŒ **Higher Initial Investment**
- Setup & configuration: 2-3 hari (~16-24 jam)
- Learning curve: perlu developer/test automation engineer
- Tool licensing (some): $100-500/month

âŒ **Maintenance Overhead**
- When UI changes, tests break
- Tests need update (refactoring)
- Flaky tests (timing issues) need fixing
- Estimated: 5-10% of development time

âŒ **Not Suitable for Everything**
- Visual/design bugs: need manual review
- UX feedback: need real user
- Exploratory testing: limited
- Accessibility: partial (need manual validation)

âŒ **Tech Debt Risk**
- Bad test code: hard to maintain
- Over-testing: overkill for simple features
- Under-testing: coverage gaps

âŒ **False Confidence**
- Test passing tidak berarti app fully works
- Missing edge cases
- Need combination with manual testing

---

### Automation Testing - Realistic Effort

```
Timeline untuk Assessment Online (39 test cases):

SETUP PHASE: 2-3 hari
  - Tool installation & configuration: 4 hours
  - Framework setup (Cypress, k6, etc): 4 hours
  - CI/CD pipeline setup: 4 hours
  - Learn testing framework: 4 hours
  Total: 16 hours (2 days)

INITIAL TEST DEVELOPMENT: 3-5 hari
  - Design test scenarios: 4 hours
  - Develop 39 test scripts: 20 hours
    (~30 min per test case untuk automation)
  - Debugging & fixing flaky tests: 8 hours
  Total: 32 hours (~4 days)

FIRST TEST RUN: 5 menit
  - 39 test cases @ ~7 sec each = 273 seconds = 4.5 menit

ISSUE FOUND & FIX CYCLE:
  - Re-run all tests: 5 menit
  - Per test update: 5-10 menit
  - For 5 fixes: 30 menit

TOTAL FIRST CYCLE: 16 + 32 + 0.25 = 48.25 hours (~1 week)

---

Maintenance (1 tahun):
  - Per feature update/UI change: 10-30 menit maintenance
  - Average: 2 updates/bulan = 40 menit/bulan
  - Per tahun: 40 min Ã— 12 = 8 hours/tahun

  - NEW FEATURES testing: 30 min per feature (estimate)
  - Average: 4 new features/bulan = 2 hours/bulan
  - Per tahun: 24 hours/tahun

TOTAL EFFORT 1 TAHUN: 48 + 8 + 24 = 80 hours
```

---

## Perbandingan Langsung (Side by Side)

### 1. Test Execution Speed

#### **Scenario: Run full test suite (39 cases)**

**MANUAL:**
```
- Setup browser & tools: 2 menit
- Run 39 test cases @ 15 menit each: 585 menit
- Document & report: 30 menit

TOTAL: 617 menit = 10.3 HOURS
```

**AUTOMATION:**
```
- Load test suite: 5 detik
- Run 39 test cases @ 7 sec each: 273 detik
- Generate report: 30 detik

TOTAL: 308 detik = 5.1 MINUTES
```

**COMPARISON:**
```
Manual: 10.3 hours
Automation: 5.1 minutes

Speed gain: 121x faster âš¡
```

---

### 2. Cost per Test Execution

#### **Scenario 1: Initial Testing (First Time)**

**MANUAL:**
```
Development & Testing person: $50/hour
Time: 62 hours
Cost: 62 Ã— $50 = $3,100
```

**AUTOMATION:**
```
Development person: $50/hour
Time: 48 hours
Cost: 48 Ã— $50 = $2,400
Plus: Tools & infrastructure: $200
Total: $2,600

Saving: $500
```

**Advantage: Automation (slightly)**

---

#### **Scenario 2: Testing Over 1 Year (5 cycles)**

**MANUAL:**
```
Requirement: 1 dedicated QA tester
Salary: $50/hour Ã— 40 hours/week Ã— 50 weeks = $100,000/year
Plus: Tools (Postman, BrowserStack): $1,000/year
Plus: Training & overhead: $2,000/year

TOTAL: $103,000/year
```

**AUTOMATION:**
```
Initial setup (1-time): 48 hours Ã— $50 = $2,400
Maintenance & new tests: 80 hours/year Ã— $50 = $4,000
Tools (free): $0
Plus: Tools (Lighthouse, k6, optional SaaS): $1,000/year

TOTAL: $7,400/year

Saving: $95,600/year (92% cost reduction!) ğŸ’°
```

---

### 3. Quality & Coverage

#### **MANUAL TESTING:**
```
Accuracy: 85-90%
Consistency: 70-80%
Coverage: 40-50% of test cases (due to time constraint)
Bug Detection Rate: 70%
Regression Bugs: 20-30% (missed in re-testing)

False Positives: 5-15% (tester error)
False Negatives: 10-20% (tester miss bugs)
```

**Example Bug:**
```
Tester lupa test password hashing pada hari ke-5
Admin dapat create user dengan plain text password
â†’ Bug goes to production
â†’ Security issue discovered by user/hacker
â†’ Hotfix cost: $5,000+
```

---

#### **AUTOMATION TESTING:**
```
Accuracy: 99%+
Consistency: 100%
Coverage: 80-90% of test cases (dapat run semua)
Bug Detection Rate: 95%+
Regression Bugs: 5-10% (caught immediately)

False Positives: 1-2% (flaky timing issues)
False Negatives: 2-5% (edge cases missed)
```

**Example Bug:**
```
Automated test untuk password hashing dijalankan
Setiap kali push code (5x/hari)
Admin tries to create user dengan plain text
â†’ Test fails immediately
â†’ Developer fix sebelum merge
â†’ Zero production bugs
```

---

### 4. Regression Prevention

#### **MANUAL:**
```
New feature added â†’ Developers nervous about breaking existing features
â†’ Minimal testing of existing features (due to time)
â†’ Regressions slip to production
â†’ Customer complains â†’ Hot fix
â†’ Cost: $2,000-5,000 per regression

Example: Ubah login flow â†’ Forgot to test logout
â†’ Logout tidak bekerja di production
â†’ Users stuck logged in
â†’ Security issue & UX nightmare
```

---

#### **AUTOMATION:**
```
New feature added â†’ All 39 test cases run automatically
â†’ Regression detected immediately (in CI/CD, before merge)
â†’ Developer fix before code merged
â†’ Zero regressions in production
â†’ Cost: $0 (prevented)

Example: Ubah login flow â†’ Logout test fails automatically
â†’ Developer sees failure in CI/CD
â†’ Developer fix the issue
â†’ Re-run test â†’ All green
â†’ Merge to main safely
```

---

### 5. Time to Production

#### **MANUAL:**
```
Monday: Developers finish coding
Tuesday-Wednesday: QA testing (16+ hours)
Thursday: Fix issues
Friday: Re-test (8+ hours)
Monday: Finally ready to production (after 5 days)

OR

Developers skip testing due to time pressure
â†’ Code pushed to production immediately
â†’ Bugs discovered by users
â†’ Emergency hot-fix weekend work
```

---

#### **AUTOMATION:**
```
Monday 5 PM: Developers finish coding
Monday 5:30 PM: Push to GitHub
Monday 5:35 PM: GitHub Actions runs all tests (5 min)
Monday 5:40 PM: Test results available

If test PASS: Code ready to production immediately
If test FAIL: Developer fix & re-run (5 min)

TOTAL: 5-15 minutes vs 5 days = 20-96x faster âš¡
```

---

## Studi Kasus Real

### Case 1: Startup Approach (Manual Testing)

**Scenario:** New startup, 3 developers, no test budget

**Decision:** Manual testing (pragmatic)

```
Week 1-4: MVP development
Week 5: Manual testing
  - Tester (1 of developers): 40 hours
  - Bugs found: 15
  - Fix & retest: 20 hours
  - Total: 60 hours
  - Ready: Day 29

Production Launch

Month 2-3: Customer bugs reported
  - Regressions: 5 bugs
  - Each hotfix: 8 hours (find, fix, retest, deploy)
  - Total: 40 hours unplanned

  - New feature request: 1 per week
  - Each feature test: 8 hours
  - Total: 32 hours/month

REALITY: 1 developer doing testing, 2 developers on features
â†’ Extremely slow feature velocity
â†’ Customers frustrated with bugs
â†’ Developers burned out
â†’ Turnover risk
```

---

### Case 2: Enterprise Approach (Automation)

**Scenario:** Medium company, 5-7 developers, budget for tools

**Decision:** Automation testing (strategic)

```
Week 1-4: MVP development
Week 5: Automation setup
  - Test automation engineer: 48 hours (setup + write tests)
  - Developers: 10 hours (integration)
  - Total: 58 hours
  - Ready: Day 26 (faster!)

Production Launch

Month 2-3: CI/CD catches regressions
  - Bugs found in CI/CD: 5 (before production)
  - Production bugs: 0-1
  - Hotfix time: 5 hours (vs 40 hours manual)

  - New feature request: 1 per week
  - Feature test automation: 4 hours/week
  - Feature development: 20 hours/week
  - Total effort: 24 hours/week (vs 28 manual)

REALITY: 5 developers all focusing on features
â†’ Fast feature velocity
â†’ Minimal production bugs
â†’ High code quality
â†’ Happy customers
â†’ Team satisfaction high
```

---

### Case 3: Real World Assessment Online ITERA

#### **Scenario A: Manual Testing Only**

```
Current: 39 test cases, 15 min per test = 9.75 hours per cycle
Frequency: Every release (2x per month)

Year 1 effort:
- Testing: 20 cycles Ã— 9.75 hours = 195 hours
- Bug fix & retest: 40 hours (70% success on first try)
- New features: 12 features Ã— 2 hours = 24 hours
- Subtotal: 259 hours

Salary (QA): 259 hours Ã— $50 = $12,950/year
Tools: Postman, BrowserStack: $1,500/year

TOTAL COST: $14,450/year

Problems:
- QA person can only test, no development
- Regressions happen: 10-15 per year Ã— $500 = $5,000-7,500
- Feature development slows down (need QA person)
- Production bugs: 3-5 per year Ã— $2,000 = $6,000-10,000

REAL TOTAL COST: $14,450 + $11,000-17,500 = $25,450-31,950/year
```

---

#### **Scenario B: Automation Testing**

```
Year 1:
- Setup & automation (48 hours): $2,400
- Maintenance & new tests (80 hours): $4,000
- Tools (free + optional SaaS): $800/year

TOTAL COST: $7,200/year

Benefits:
- Regressions prevented: 90% Ã— 10 Ã— $500 = $4,500 saved
- Production bugs prevented: 80% Ã— 4 Ã— $2,000 = $6,400 saved
- Feature velocity: +40% (developers not waiting for QA) = +$20,000
- Code quality: Better refactoring â†’ Technical debt -20% = +$10,000

REAL TOTAL BENEFIT: $7,200 + $4,500 + $6,400 + $20,000 + $10,000 = $48,100/year

NET BENEFIT: $48,100 - $7,200 = $40,900/year profit! ğŸ’°
```

**ROI: 570% in Year 1**

---

## Cost & ROI Analysis

### Total Cost of Ownership (3 years)

#### **Manual Testing Only**

```
Year 1:
- QA Tester salary: $50,000
- Testing tools: $1,500
- Bug fixes (production): $15,000
SUBTOTAL: $66,500

Year 2:
- QA Tester salary: $52,500 (+5% raise)
- Testing tools: $1,500
- Bug fixes: $12,000 (slightly better)
SUBTOTAL: $66,000

Year 3:
- QA Tester salary: $55,000 (+5% raise)
- Testing tools: $1,500
- Bug fixes: $10,000
SUBTOTAL: $66,500

3-YEAR TOTAL: $199,000
```

---

#### **Automation Testing**

```
Year 1:
- Developer time (automation setup): $2,400
- Testing tools: $800
- Bug fixes prevented: -$6,000 (saved)
SUBTOTAL: -$2,800 (net saving!)

Year 2:
- Developer time (maintenance): $4,000
- Testing tools: $800
- Bug fixes prevented: -$8,000 (saved)
SUBTOTAL: -$3,200 (net saving!)

Year 3:
- Developer time (maintenance): $4,000
- Testing tools: $800
- Bug fixes prevented: -$8,000 (saved)
SUBTOTAL: -$3,200 (net saving!)

3-YEAR TOTAL: -$9,200 (actually saving money!)
```

---

### ROI Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    COST COMPARISON (3 Years)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Manual Testing:    $199,000          â”‚
â”‚ Automation:        -$9,200 (saving)  â”‚
â”‚                                      â”‚
â”‚ Difference:        $208,200          â”‚
â”‚ ROI:               2,882% (automation)
â”‚                                      â”‚
â”‚ Payback Period:    3 weeks           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Hybrid Approach (Recommended)

### Best of Both Worlds

**Kombinasi Manual + Automation:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HYBRID TESTING STRATEGY                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  AUTOMATION (80% effort, 95% coverage)          â”‚
â”‚  â”œâ”€ Security (OWASP ZAP, SonarQube)             â”‚
â”‚  â”œâ”€ Performance (Lighthouse, k6)                â”‚
â”‚  â”œâ”€ E2E workflows (Cypress, Playwright)         â”‚
â”‚  â”œâ”€ Compatibility (Playwright cross-browser)    â”‚
â”‚  â””â”€ Regression testing (CI/CD)                  â”‚
â”‚                                                  â”‚
â”‚  MANUAL (20% effort, but critical)              â”‚
â”‚  â”œâ”€ Visual/design testing                       â”‚
â”‚  â”œâ”€ UX testing (5-10 real users)                â”‚
â”‚  â”œâ”€ Exploratory testing (monkey testing)        â”‚
â”‚  â”œâ”€ Accessibility (screen reader)               â”‚
â”‚  â””â”€ Ad-hoc testing                              â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Hybrid Implementation for Assessment Online

#### **Phase 1: Quick Setup (Week 1)**
```
Automation:
- Setup Cypress for E2E: 8 hours
- Setup k6 for load testing: 4 hours
- Setup GitHub Actions: 4 hours
Total: 16 hours

Manual:
- UX testing dengan 5 mahasiswa: 10 hours
Total: 10 hours

WEEK 1 TOTAL: 26 hours (~3 days of work)
```

---

#### **Phase 2: Ongoing (Per Month)**

```
Automation (recurring):
- Maintain/update tests: 5 hours/month
- Run on every PR: 0 hours (automated)
- Fix flaky tests: 2 hours/month
Total: 7 hours/month

Manual (recurring):
- UX testing new features: 4 hours/month (optional)
- Accessibility spot-check: 2 hours/month
- Security exploratory testing: 3 hours/month
Total: 9 hours/month (flexible)

MONTHLY TOTAL: 16 hours/month (2 days) = 80% automation, 20% manual
```

---

#### **Coverage Achievement**

```
BEFORE (Manual only):
  Security:       40%
  Performance:    30%
  Usability:      50%
  Compatibility:  35%
  Average:        39% COVERAGE

AFTER (Hybrid):
  Security:       95% (automated)
  Performance:    90% (automated)
  Usability:      85% (60% automated + 25% manual UX)
  Compatibility:  95% (automated)
  Average:        91% COVERAGE â¬†ï¸ 2.3x improvement!
```

---

## Decision Matrix

### Choose Manual If:

âœ… **Quick MVP** - Need to launch in 1-2 weeks
- Setup automation overhead too high
- Testing can be done by developer (not dedicated QA)

âœ… **One-Time Project** - No long-term maintenance
- Example: POC, contractor project
- No need for regression testing infrastructure

âœ… **Visual Heavy** - Mostly design/UI testing
- Mobile app design
- Marketing website
- Visual consistency check

âœ… **Exploratory** - Need creative testing
- Finding edge cases
- User behavior unpredictable
- Novel application

---

### Choose Automation If:

âœ… **Ongoing Product** - Long-term maintenance expected
- SaaS application
- Active feature development
- Regular releases (2+ per month)

âœ… **Large Team** - Multiple developers
- Regression risk high
- Code changes frequent
- Need confidence to refactor

âœ… **Quality Critical** - Cannot afford bugs in production
- Healthcare/Finance systems
- User-facing critical features
- Compliance required

âœ… **Performance Important** - Load testing needed
- Need to handle 100+ concurrent users
- Response time targets

âœ… **Cost Sensitive** - Long-term budget limited
- Automation ROI positive after 3-6 months
- Salary savings for QA person

---

### Choose Hybrid If:

âœ… **Balanced Approach** (RECOMMENDED for Assessment Online)

```
Assessment Online Characteristics:
âœ… Ongoing product (AUTOMATION good)
âœ… Active development (AUTOMATION needed)
âœ… UX/design important (MANUAL needed)
âœ… Security critical (AUTOMATION essential)
âœ… Budget conscious (AUTOMATION saves money)
âœ… Team of 5-10 developers (AUTOMATION needed)

Decision: HYBRID APPROACH (80/20)
```

---

## Decision Tree

```
START: Need to test application

  â†“ Have 2+ weeks until launch?
  â”œâ”€ YES â†’ Continue
  â””â”€ NO  â†’ Use MANUAL (quick start)

  â†“ Will you continue developing after launch?
  â”œâ”€ NO  â†’ Use MANUAL (one-time only)
  â””â”€ YES â†’ Continue

  â†“ Have budget for 1-3 days setup?
  â”œâ”€ NO  â†’ Use MANUAL (budget constraint)
  â””â”€ YES â†’ Continue

  â†“ Need to detect regressions automatically?
  â”œâ”€ NO  â†’ Use MANUAL (simpler)
  â””â”€ YES â†’ Continue

  â†“ Can afford occasional bugs in production?
  â”œâ”€ YES â†’ Use MANUAL or Light AUTOMATION
  â””â”€ NO  â†’ Use AUTOMATION

RESULT:
  FULL AUTOMATION: Quick MVP with ongoing support
  HYBRID (80/20): Balanced, recommended for most
  MANUAL ONLY: One-time projects, tight timeline
```

---

## Recommendation for Assessment Online ITERA

### Strategic Decision: **HYBRID APPROACH (80% Automation / 20% Manual)**

### Implementation Timeline:

**Week 1: Setup & Initial Automation**
```
Monday:
- Setup Cypress: 4 hours
- Create first 10 E2E tests: 4 hours

Tuesday:
- Create k6 load test script: 3 hours
- Setup GitHub Actions: 3 hours
- Manual UX testing (5 users): 4 hours

Wednesday:
- Complete remaining 29 tests: 8 hours
- Fix flaky tests: 2 hours
- Setup SonarQube: 2 hours

Thursday-Friday:
- Buffer for issues: 10 hours
- Documentation: 4 hours
- Training team: 4 hours

TOTAL: ~48 hours = 1 week full-time
```

---

**Week 2+: Ongoing Testing**

```
Per Release (2x per month):
- Manual UX testing: 3 hours
- Automation (CI/CD): 5 minutes (automated)
- Report & documentation: 1 hour
Total: 4 hours per release

Monthly: 8 hours (1 day)
Yearly: 96 hours (12 days)

Cost: 96 Ã— $50 = $4,800/year (vs $50,000 manual QA person)
```

---

### Expected Outcomes:

```
BEFORE (Current State):
- Testing: Manual via developer + incomplete
- Coverage: ~40%
- Time to test: N/A (not systematically done)
- Production bugs: 2-3 per release

AFTER (Hybrid Automation):
- Testing: Automated 80% + manual 20%
- Coverage: 90%+
- Time to test: 5 minutes (CI/CD automatic)
- Production bugs: 0-1 per release (90% reduction)

BENEFITS:
âœ… 90% bug reduction
âœ… 200+ hours/year time saved
âœ… $40,000+ cost saving
âœ… Higher code quality
âœ… Faster feature velocity
âœ… More confident releases
```

---

## Conclusion

### TL;DR

| Aspect | Manual | Automation | Winner |
|--------|--------|-----------|--------|
| **Setup Difficulty** | Easy | Complex | Manual |
| **Speed (per run)** | 10+ hours | 5 minutes | Automation (120x) |
| **Year 1 Cost** | $66,500 | $7,200 | Automation (90% cheaper) |
| **3-Year ROI** | -$0 (break-even) | +$208,000 | Automation (2,882% ROI) |
| **Quality** | 85% | 99% | Automation |
| **Coverage** | 40% | 90% | Automation |
| **Scalability** | Poor | Excellent | Automation |
| **Recommended** | Startups | Growing companies | **HYBRID** |

---

### Final Verdict

**âŒ Manual Only:** Viable for MVP/startup, not sustainable long-term

**âœ… Automation:** Best for ongoing product, significant ROI

**ğŸ† Hybrid (Recommended):** Best of both worlds, achieves 90%+ quality with managed effort

**For Assessment Online ITERA: Use HYBRID approach (80% automation, 20% manual) for optimal results**

---

**Dokumen Dibuat:** 26 November 2025
**Status:** Analisis Komprehensif Complete
**Version:** 1.0
**Author:** Assessment Online ITERA Team

---

**END OF DOCUMENT**
